## Machine Learning for Time Series Forecasting - Code Repository

![Python 3.6](https://img.shields.io/badge/python-3.6-success.svg)
![Python 3.7](https://img.shields.io/badge/python-3.7-success.svg)
![Python 3.8](https://img.shields.io/badge/python-3.8-success.svg)
![License](https://img.shields.io/badge/license-BSD-success.svg)

Published May, 2021

#TODO
## ADD LINKS WITH REFERRAL CODES

[<img src="./mltsf.png" width="248">](https://www.udemy.com/course/machine-learning-for-time-series-forecasting)  [<img src="./trainindata.png" width="248">](https://www.trainindata.com)

## Links

- [Online Course](https://www.udemy.com/course/machine-learning-for-time-series-forecasting)


## Table of Contents

TBD, leave this curriculum as template.

1. **Basic Selection Methods**
	1. Removing Constant Features
	2. Removing Quasi-Constant Features
	3. Removing Duplicated Features

2. **Correlation Feature Selection**
	1. Removing Correlated Features 
	2. Basic Selection Methods + Correlation - Pipeline

3. **Filter Methods: Univariate Statistical Methods**
	1. Mutual Information
	2. Chi-square distribution
	3. Anova
	4. Basic Selection Methods + Statistical Methods - Pipeline

4. **Filter Methods: Other Methods and Metrics**
	1. Univariate roc-auc, mse, etc
	2. Method used in a KDD competition - 2009

5. **Wrapper Methods**
	1. Step Forward Feature Selection
	2. Step Backward Feature Selection
	3. Exhaustive Feature Selection

6. **Embedded Methods: Linear Model Coefficients**
	1. Logistic Regression Coefficients
	2. Linear Regression Coefficients
	3. Effect of Regularization on Coefficients
	4. Basic Selection Methods + Correlation + Embedded - Pipeline 

7. **Embedded Methods: Lasso**
	1. Lasso 
	2. Basic Selection Methods + Correlation + Lasso - Pipeline 

8. **Embedded Methods: Tree Importance**
	1. Random Forest derived Feature Importance
	2. Tree importance + Recursive Feature Elimination
	3. Basic Selection Methods + Correlation + Tree importance - Pipeline

9. **Hybrid Feature Selection Methods**
	1. Feature Shuffling
	2. Recursive Feature Elimination
	3. Recursive Feature Addition
