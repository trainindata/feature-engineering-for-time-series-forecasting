{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "artificial-conversation",
   "metadata": {},
   "source": [
    "In this notebook we will:\n",
    "1) Provide instructions to download the retail sales dataset\n",
    "2) Create processed versions of the time series for later use in the course\n",
    "3) Save the time series data for use in the course\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "statistical-ceramic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-arcade",
   "metadata": {},
   "source": [
    "# Get the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-community",
   "metadata": {},
   "source": [
    "The dataset can be obtained from this [link](https://raw.githubusercontent.com/facebook/prophet/master/examples/example_air_passengers.csv). It will open a raw file in GitHub. A simple way of obtaining the data is to copy and paste the values from your browser into a text editor of your choice. \n",
    "Save it in the Datasets directory with the filename `example_retail_sales.csv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "younger-albuquerque",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Datasets/example_retail_sales.csv', parse_dates=['ds'], index_col=['ds'], nrows=160)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-dinner",
   "metadata": {},
   "source": [
    "# Create dataset with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "verbal-jewel",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_missing_data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "complex-hudson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert missing data into dataframe\n",
    "df_with_missing_data.iloc[10:11] = np.NaN\n",
    "df_with_missing_data.iloc[25:28] = np.NaN\n",
    "df_with_missing_data.iloc[40:45] = np.NaN\n",
    "df_with_missing_data.iloc[70:94] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "whole-council",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset in Datasets directory\n",
    "df_with_missing_data.to_csv('../Datasets/example_retail_sales_with_missing_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-petroleum",
   "metadata": {},
   "source": [
    "# Create dataset with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "authorized-canon",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_outliers = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "biological-laptop",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert outliers into dataframe\n",
    "outlier_idx = [20,33,66,150]\n",
    "df_with_outliers.iloc[outlier_idx] = df_with_outliers.iloc[outlier_idx]*1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "every-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset in Datasets directory\n",
    "df_with_outliers.to_csv('../Datasets/example_retail_sales_with_outliers.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
